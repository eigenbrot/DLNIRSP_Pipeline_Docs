Data Reduction Walkthrough
==========================

Input Data
----------
For this walkthrough we will use a set of fake data generated by DL's fake data generation script, ``dl_fake_data``,
which generates a full suite of input data. You will need some DL-NIRSP simulations to do this; ask either A. Eigenbrot
or S. Jaeggli. Let's assume those simulations live in a folder called Camera2:

.. code-block:: console

  $ dl_fake_data -p Camera2 raw
  ...
  $ ls -1 raw
  DLNIRSP_20160522T000001.000000_0.fits
  DLNIRSP_20160522T000001.033333_1.fits
  DLNIRSP_20160522T000001.066667_2.fits
  DLNIRSP_20160522T000001.100000_3.fits
  DLNIRSP_20160522T000001.133333_4.fits
  DLNIRSP_20160522T000001.166667_5.fits
  DLNIRSP_20160522T000001.200000_6.fits
  DLNIRSP_20160522T000001.233334_7.fits
  DLNIRSP_20160522T001003.266667_0.fits
  ...

Unless you have a pre-computed IFU Calibration object then you will also need a set of knife-edge scan data. These take
a very long time to produce. They also require a subdirectory in the Simulation directory called "knife-edge_scan". To
make the images, simply pass the `-k` option to ``dl_fake_data``.

.. code-block:: console

  $ ls -1 Camera2
  ...
  knife-edge_scan

  $ dl_fake_data -p Camera2 -k raw_knife
  ...

PolCal Data
-----------
We'll also need a set of DL-NIRSP data from a PolCal run. This can be generated by the
`PA&C Modules' <https://bitbucket.org/dkistdc/pac-pipeline/src/master/>`_ own ``gen_fake_data.py``.

Before we do that, however, we need a mask that tells the PA&C Modules where the data gaps in DL-NIRSP are. To do this
use ``dl_polcal_mask`` and point it at the fake data you just generated:

.. code-block:: console

  $ dl_polcal_mask raw polcal_mask.fits
  ...
  $ ls -1
  Camera2
  polcal_mask.fits
  raw

Now call PA&C's script:

.. code-block:: console

  $ ../pac-pipeline/PAC_Pipeline/utils/gen_fake_data.py -I dlnirsp -m polcal_mask.fits polcal
  ...
  $ ls -1 polcal
  DLNIRSP_20160523T000000.000000_0.fits
  DLNIRSP_20160523T000001.000000_1.fits
  DLNIRSP_20160523T000002.000000_2.fits
  DLNIRSP_20160523T000003.000000_3.fits
  DLNIRSP_20160523T000004.000000_4.fits
  DLNIRSP_20160523T000005.000000_5.fits
  DLNIRSP_20160523T000006.000000_6.fits
  DLNIRSP_20160523T000007.000000_7.fits
  DLNIRSP_20160523T000015.000000_0.fits
  DLNIRSP_20160523T000016.000000_1.fits
  ...

Knife-edge Scan Data
--------------------
We'll also need a boat load of knife-edge scan observations. Generate via:

.. code-block:: console

  $ ./DLNIRSP_Pipeline/utils/gen_fake_data -p SIM_DIR -k raw_knife
  ...
  $ ls -1 raw_knife
  DLNIRSP_20160521T000001.000000_0.fits
  DLNIRSP_20160521T000002.033334_0.fits
  DLNIRSP_20160521T000003.066667_0.fits
  DLNIRSP_20160521T000004.100000_0.fits
  DLNIRSP_20160521T000005.133334_0.fits
  ...

Setup
-----
Now let's create a default config file:

.. code-block:: console

  $ mkdir rdx
  $ cd rdx
  $ dl_pipeline -b config.ini

Now we'll need to populate the config file, which should be pretty straight forward.

.. code-block:: ini

  [Main]
  raw_sci_dir = raw
  dataset_id =
  output_prefix = rdx/Sci
  dark_cal = DarkCal
  instrument_pol_cal = InstPolCal
  lamp_gain_cal = LampCal
  solar_gain_cal = SolarCal
  geometric_cal = GeoCal
  ifu_cal = IFUCal
  cube_shape = (200, 200)
  threads = 4

  [DarkCalibration]
  raw_dark_dir = raw

  [InstrumentPolarization]
  raw_pol_dir = polcal
  raw_pol_dark_dir = raw
  threads = 4

  [LampGainCalibration]
  raw_lamp_gain_dir = raw

  [SolarGainCalibration]
  raw_solar_gain_dir = raw

  [IFUCalibration]
  raw_knife_dir = raw_knife
  threads = 4

Run
---
This is the easy part, just call the pipeline

.. code-block:: console

  $ dl_pipeline config.ini

Creating the IFU Calibration can take a very long time (O(hour)), but after that each individual data objects reduces relatively quickly.

The DL-NIRSP Pipeline produces a lot of status messages and it is usually a good idea to save these somewhere so you can see exactly
what was done to the data at a later time (and find any error messages). To do this I usually run the pipeline as

.. code-block:: console

  $ dl_pipeline config.ini 2>&1 | tee spool.txt

On most systems this will cause your terminal (stdout) to update much less frequently than usual. This is due to how
python decides to flush its buffer to stdout. If you want to save a spool file *and* get real-time status messages then
you need to set the environmental variable `PYTHONUNBUFFERED=yes`.

Output Data
-----------
If your config file looks like the one above then your reduction directory will now look like this

.. code-block:: console

  $ ls -1
  config.ini
  DarkCal.fits
  DarkCal_savg.asdf
  DarkCal_sig.fits
  GeoCal.asdf
  IFUCal.asdf
  InstPolCal.fits
  knife_proc
  LampCal.fits
  LampCal_sig.fits
  Sci_0000-0002-0002.fits
  Sci_0001-0002-0002.fits
  ...
  SolarCal.fits
  SolarCal_sig.fits
  spool.txt

All of the ``*Cal*`` files are the intermediate data products used by the pipeline whose names are specified in the
config file.

The processed data live in ``Sci_RRRR-XXXX-YYYY.fits``. These files each contain a single Primary HDU with no data and 4
ImageHDUs, one for each of the four Stokes vectors. Each of these ImageHDUs will have 3D data (wave, x, y).
The ``RRRR-XXXX-YYYY`` corresponds to the ``R``\epeat number for mosaic position (``X``, ``Y``).